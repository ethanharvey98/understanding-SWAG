{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class CyclicLR(torch.optim.lr_scheduler._LRScheduler):\n",
    "    def __init__(self, optimizer, lr_0, T, M, last_epoch=-1):\n",
    "        self.lr_0 = lr_0\n",
    "        self.T = T\n",
    "        self.M = M\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        epoch = self.last_epoch // (self.T // self.M)\n",
    "        batch_idx = self.last_epoch % (self.T // self.M)\n",
    "        rcounter = epoch * (self.T // self.M) + batch_idx\n",
    "        cos_inner = np.pi * (rcounter % (self.T // self.M))\n",
    "        cos_inner /= self.T // self.M\n",
    "        cos_out = np.cos(cos_inner) + 1\n",
    "        lr = 0.5 * cos_out * self.lr_0\n",
    "        return [lr for _ in self.optimizer.param_groups]\n",
    "\n",
    "# Sample model parameter\n",
    "epochs = 100\n",
    "batches = 2\n",
    "T = epochs\n",
    "M = 5\n",
    "model = torch.nn.Linear(10, 2)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# Define the CosineAnnealingLR scheduler\n",
    "\n",
    "scheduler = CyclicLR(optimizer, 0.1, T, M)\n",
    "\n",
    "# Store learning rates for each epoch\n",
    "lrs = []\n",
    "reds = []\n",
    "\n",
    "# Simulate 10 epochs\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for _ in range(batches):\n",
    "        optimizer.step()\n",
    "        \n",
    "    lrs.append(scheduler.get_last_lr()[0])\n",
    "    scheduler.step()\n",
    "    if epoch%(T//M) == (T//M)-1:\n",
    "        print(epoch//(T//M))\n",
    "        reds.append(1)\n",
    "    else:\n",
    "        reds.append(0)\n",
    "\n",
    "        \n",
    "# Plot the learning rates\n",
    "plt.plot(range(len(lrs)), lrs, marker='o')\n",
    "plt.plot(range(len(reds)), reds, marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('CosineAnnealingLR over 10 epochs')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "def flatten_params(model, deepcopy=True):\n",
    "    if deepcopy: model = copy.deepcopy(model)\n",
    "    return torch.cat([param.detach().view(-1) for param in model.parameters()])\n",
    "\n",
    "#weights = torchvision.models.ResNet50_Weights.IMAGENET1K_V1\n",
    "#model = torchvision.models.resnet50(weights=weights)\n",
    "\n",
    "model = torchvision.models.resnet50()\n",
    "checkpoint = torch.load('/cluster/home/eharve06/understanding-SWAG/experiments/ImageNet_v1_torchvision_cSGD=batch/ImageNet_v1_torchvision_cSGD=batch_random_state=1001_4.pt')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "model.fc = torch.nn.Identity()\n",
    "\n",
    "torch.save(flatten_params(model), '/cluster/tufts/hugheslab/eharve06/torchvision-checkpoints/5.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize(size=176),\n",
    "    torchvision.transforms.CenterCrop(size=224),\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "val_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize(size=232),\n",
    "    torchvision.transforms.CenterCrop(size=224),\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "train_dataset = torchvision.datasets.ImageFolder(root='/cluster/tufts/hugheslab/datasets/ImageNet/train/', transform=train_transform)\n",
    "val_dataset = torchvision.datasets.ImageFolder(root='/cluster/tufts/hugheslab/datasets/ImageNet/val/', transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset_indices = torch.randperm(len(train_dataset))[:1000]\n",
    "train_subset_dataset = torch.utils.data.Subset(train_dataset, train_subset_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "X = torch.stack([image for image, label in train_subset_dataset])\n",
    "dist = X.view(X.shape[0], -1)@(-1*X.view(X.shape[0], -1)).t()\n",
    "y = torch.stack([torch.tensor(label) for image, label in train_subset_dataset])\n",
    "one_hot_y = torch.nn.functional.one_hot(y, num_classes=1_000)\n",
    "with torch.no_grad():\n",
    "    m = f(X)\n",
    "    \n",
    "dist, one_hot_y, m = dist.detach().numpy(), one_hot_y.detach().numpy(), m.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000.    1.]\n",
      "[1.e+03 1.e+00]\n",
      "[1000.            1.00000001]\n",
      "[ 1.e+03 -1.e-02]\n",
      "[ 1.e+03 -1.e-02]\n",
      "[ 1.0000000e+03 -9.9999851e-03]\n",
      "[1000.     -4.05]\n",
      "[1000.00000001   -4.05      ]\n",
      "[1000.           -4.04999999]\n",
      "[1000.    -20.21]\n",
      "[1000.00000001  -20.21      ]\n",
      "[1000.          -20.20999999]\n",
      "[1000.    -84.85]\n",
      "[1000.00000001  -84.85      ]\n",
      "[1000.          -84.84999999]\n",
      "[1000.   -343.41]\n",
      "[1000.00000001 -343.41      ]\n",
      "[1000.         -343.40999999]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_225763/926920329.py:10: RuntimeWarning: invalid value encountered in log\n",
      "  logdet = -(1/2)*np.log(np.linalg.det(K+softplus_np(params[1])*np.eye(R)))\n",
      "/tmp/ipykernel_225763/926920329.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "  logdet = -(1/2)*np.log(np.linalg.det(K+softplus_np(params[1])*np.eye(R)))\n",
      "/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/bdl-transfer-learning/lib/python3.8/site-packages/scipy/optimize/_numdiff.py:576: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[370], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m(const \u001b[38;5;241m+\u001b[39m logdet \u001b[38;5;241m+\u001b[39m kernel_term)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimize\n\u001b[0;32m---> 16\u001b[0m learned_hypers \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneg_MLL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1e3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m learned_hypers\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/bdl-transfer-learning/lib/python3.8/site-packages/scipy/optimize/_minimize.py:691\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    689\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_cg(fun, x0, args, jac, callback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbfgs\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 691\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_bfgs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton-cg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    693\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    694\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/bdl-transfer-learning/lib/python3.8/site-packages/scipy/optimize/_optimize.py:1388\u001b[0m, in \u001b[0;36m_minimize_bfgs\u001b[0;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, finite_diff_rel_step, xrtol, **unknown_options)\u001b[0m\n\u001b[1;32m   1385\u001b[0m pk \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mdot(Hk, gfk)\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1387\u001b[0m     alpha_k, fc, gc, old_fval, old_old_fval, gfkp1 \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m-> 1388\u001b[0m              \u001b[43m_line_search_wolfe12\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmyfprime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgfk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1389\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mold_fval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mold_old_fval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mamin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mamax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _LineSearchError:\n\u001b[1;32m   1391\u001b[0m     \u001b[38;5;66;03m# Line search failed to find a better solution.\u001b[39;00m\n\u001b[1;32m   1392\u001b[0m     warnflag \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/bdl-transfer-learning/lib/python3.8/site-packages/scipy/optimize/_optimize.py:1160\u001b[0m, in \u001b[0;36m_line_search_wolfe12\u001b[0;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, **kwargs)\u001b[0m\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;124;03mSame as line_search_wolfe1, but fall back to line_search_wolfe2 if\u001b[39;00m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;124;03msuitable step length is not found, and raise an exception if a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \n\u001b[1;32m   1156\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m extra_condition \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextra_condition\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1160\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mline_search_wolfe1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfprime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgfk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mold_fval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mold_old_fval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m extra_condition \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m     xp1 \u001b[38;5;241m=\u001b[39m xk \u001b[38;5;241m+\u001b[39m ret[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m pk\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/bdl-transfer-learning/lib/python3.8/site-packages/scipy/optimize/_linesearch.py:84\u001b[0m, in \u001b[0;36mline_search_wolfe1\u001b[0;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, args, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mdot(gval[\u001b[38;5;241m0\u001b[39m], pk)\n\u001b[1;32m     82\u001b[0m derphi0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(gfk, pk)\n\u001b[0;32m---> 84\u001b[0m stp, fval, old_fval \u001b[38;5;241m=\u001b[39m \u001b[43mscalar_search_wolfe1\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mphi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mderphi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mold_fval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mold_old_fval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mderphi0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mc1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mamax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mamin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxtol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stp, fc[\u001b[38;5;241m0\u001b[39m], gc[\u001b[38;5;241m0\u001b[39m], fval, old_fval, gval[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/bdl-transfer-learning/lib/python3.8/site-packages/scipy/optimize/_linesearch.py:160\u001b[0m, in \u001b[0;36mscalar_search_wolfe1\u001b[0;34m(phi, derphi, phi0, old_phi0, derphi0, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    159\u001b[0m     alpha1 \u001b[38;5;241m=\u001b[39m stp\n\u001b[0;32m--> 160\u001b[0m     phi1 \u001b[38;5;241m=\u001b[39m \u001b[43mphi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m     derphi1 \u001b[38;5;241m=\u001b[39m derphi(stp)\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/bdl-transfer-learning/lib/python3.8/site-packages/scipy/optimize/_linesearch.py:75\u001b[0m, in \u001b[0;36mline_search_wolfe1.<locals>.phi\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mphi\u001b[39m(s):\n\u001b[1;32m     74\u001b[0m     fc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/bdl-transfer-learning/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:267\u001b[0m, in \u001b[0;36mScalarFunction.fun\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 267\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/bdl-transfer-learning/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 251\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/bdl-transfer-learning/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/bdl-transfer-learning/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "Cell \u001b[0;32mIn[370], line 9\u001b[0m, in \u001b[0;36mneg_MLL\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m      7\u001b[0m R, R \u001b[38;5;241m=\u001b[39m dist\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m      8\u001b[0m K \u001b[38;5;241m=\u001b[39m rbf_kernel(dist, params[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m----> 9\u001b[0m kernel_term \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m*\u001b[39m(one_hot_y\u001b[38;5;241m-\u001b[39mm)\u001b[38;5;241m.\u001b[39mT\u001b[38;5;129m@np\u001b[39m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43msoftplus_np\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m@\u001b[39m(one_hot_y\u001b[38;5;241m-\u001b[39mm)\n\u001b[1;32m     10\u001b[0m logdet \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog(np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mdet(K\u001b[38;5;241m+\u001b[39msoftplus_np(params[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39meye(R)))\n\u001b[1;32m     11\u001b[0m const \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m(R\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mpi)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/bdl-transfer-learning/lib/python3.8/site-packages/numpy/linalg/linalg.py:538\u001b[0m, in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    536\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    537\u001b[0m extobj \u001b[38;5;241m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[0;32m--> 538\u001b[0m ainv \u001b[38;5;241m=\u001b[39m \u001b[43m_umath_linalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(ainv\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/bdl-transfer-learning/lib/python3.8/site-packages/numpy/linalg/linalg.py:89\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingular matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "def softplus_np(x): return np.log1p(np.exp(-np.abs(x))) + np.maximum(x, 0)\n",
    "\n",
    "def rbf_kernel(dist, ls):\n",
    "    return np.exp(-(1. / ls / 2) * (dist ** 2))\n",
    "\n",
    "def neg_MLL(params):\n",
    "    R, R = dist.shape\n",
    "    K = rbf_kernel(dist, params[0])\n",
    "    kernel_term = -(1/2)*(one_hot_y-m).T@np.linalg.inv(K+softplus_np(params[1])*np.eye(R))@(one_hot_y-m)\n",
    "    logdet = -(1/2)*np.log(np.linalg.det(K+softplus_np(params[1])*np.eye(R)))\n",
    "    const = -(R/2)*np.log(2*np.pi)\n",
    "    print(params)\n",
    "    return -(const + logdet + kernel_term).sum()\n",
    "\n",
    "from scipy import optimize\n",
    "learned_hypers = optimize.minimize(neg_MLL, x0=np.array([1e3, 1.0]), tol=1e-100)\n",
    "learned_hypers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        ...,\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         1.3392e-28],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 1.3392e-28,\n",
       "         0.0000e+00]])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = X.shape[0]\n",
    "K = rbf_kernel(X, X, 1e3, 1.0)\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119145200.0 Parameter containing:\n",
      "tensor(1000., requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145200.0 Parameter containing:\n",
      "tensor(1000.1000, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145200.0 Parameter containing:\n",
      "tensor(1000.2000, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145200.0 Parameter containing:\n",
      "tensor(1000.2999, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145200.0 Parameter containing:\n",
      "tensor(1000.4000, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145200.0 Parameter containing:\n",
      "tensor(1000.5000, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145200.0 Parameter containing:\n",
      "tensor(1000.6000, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145200.0 Parameter containing:\n",
      "tensor(1000.7001, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145200.0 Parameter containing:\n",
      "tensor(1000.8001, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145200.0 Parameter containing:\n",
      "tensor(1000.9001, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145200.0 Parameter containing:\n",
      "tensor(1001.0002, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145200.0 Parameter containing:\n",
      "tensor(1001.1003, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145200.0 Parameter containing:\n",
      "tensor(1001.2004, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145200.0 Parameter containing:\n",
      "tensor(1001.3005, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145200.0 Parameter containing:\n",
      "tensor(1001.4006, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145200.0 Parameter containing:\n",
      "tensor(1001.5007, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145200.0 Parameter containing:\n",
      "tensor(1001.6009, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145200.0 Parameter containing:\n",
      "tensor(1001.7010, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145200.0 Parameter containing:\n",
      "tensor(1001.8013, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145200.0 Parameter containing:\n",
      "tensor(1001.9015, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1002.0017, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1002.1020, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1002.2023, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1002.3026, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1002.4030, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1002.5033, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1002.6037, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1002.7041, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1002.8046, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1002.9050, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1003.0056, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1003.1061, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1003.2067, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1003.3073, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1003.4079, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1003.5085, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1003.6093, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1003.7100, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1003.8107, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1003.9116, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1004.0124, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1004.1133, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1004.2142, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1004.3151, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1004.4161, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1004.5171, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1004.6181, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1004.7192, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1004.8203, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1004.9214, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1005.0226, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1005.1238, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1005.2251, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1005.3264, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1005.4277, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1005.5291, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1005.6305, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1005.7319, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145192.0 Parameter containing:\n",
      "tensor(1005.8334, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1005.9349, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1006.0365, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1006.1381, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1006.2397, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1006.3414, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1006.4431, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1006.5448, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1006.6465, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1006.7484, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1006.8502, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1006.9521, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1007.0540, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1007.1559, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1007.2579, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1007.3600, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1007.4620, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1007.5641, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1007.6663, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1007.7684, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1007.8707, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1007.9729, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1008.0752, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1008.1776, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1008.2799, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1008.3823, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1008.4847, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1008.5872, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1008.6898, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1008.7923, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1008.8949, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1008.9975, requires_grad=True) tensor(1.) tensor(1.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119145184.0 Parameter containing:\n",
      "tensor(1009.1002, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1009.2029, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1009.3056, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1009.4084, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1009.5112, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1009.6140, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1009.7169, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1009.8198, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1009.9228, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1010.0258, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1010.1288, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1010.2319, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1010.3350, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1010.4382, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1010.5414, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1010.6446, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1010.7479, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1010.8511, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1010.9545, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1011.0579, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1011.1613, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1011.2647, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1011.3682, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1011.4717, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1011.5753, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1011.6789, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1011.7825, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1011.8862, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1011.9899, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1012.0937, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1012.1974, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1012.3013, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1012.4052, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1012.5090, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1012.6130, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1012.7169, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1012.8209, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1012.9250, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1013.0291, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1013.1332, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1013.2374, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1013.3416, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1013.4458, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1013.5500, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1013.6544, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1013.7587, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1013.8631, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1013.9675, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1014.0720, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1014.1765, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1014.2810, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1014.3856, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1014.4902, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1014.5948, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1014.6995, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1014.8042, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1014.9089, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1015.0137, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1015.1186, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1015.2234, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1015.3284, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1015.4333, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1015.5383, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1015.6433, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1015.7484, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1015.8535, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1015.9586, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1016.0637, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1016.1689, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1016.2742, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1016.3795, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1016.4847, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1016.5901, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1016.6955, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1016.8009, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1016.9064, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1017.0118, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1017.1174, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1017.2230, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1017.3286, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1017.4342, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1017.5399, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1017.6456, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1017.7514, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1017.8572, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1017.9630, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1018.0689, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1018.1748, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1018.2808, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1018.3867, requires_grad=True) tensor(1.) tensor(1.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119145184.0 Parameter containing:\n",
      "tensor(1018.4927, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1018.5988, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1018.7049, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1018.8110, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1018.9172, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1019.0234, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1019.1296, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1019.2359, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1019.3422, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1019.4485, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1019.5549, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1019.6614, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1019.7678, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1019.8743, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1019.9809, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1020.0875, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1020.1941, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1020.3007, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1020.4074, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1020.5142, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1020.6209, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1020.7277, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1020.8345, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1020.9414, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1021.0483, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1021.1553, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1021.2623, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1021.3693, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1021.4763, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1021.5834, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1021.6906, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1021.7977, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1021.9049, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1022.0121, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1022.1194, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1022.2267, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1022.3341, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1022.4415, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1022.5489, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1022.6564, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1022.7639, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1022.8714, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1022.9789, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1023.0865, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1023.1942, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1023.3019, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1023.4096, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1023.5173, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1023.6251, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1023.7330, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1023.8408, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1023.9487, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1024.0566, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1024.1647, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1024.2727, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1024.3807, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1024.4888, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1024.5969, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1024.7051, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1024.8132, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1024.9215, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1025.0298, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1025.1381, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1025.2465, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1025.3549, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1025.4633, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1025.5717, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1025.6802, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1025.7887, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1025.8972, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1026.0059, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1026.1145, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1026.2231, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1026.3319, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1026.4407, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1026.5494, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1026.6582, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1026.7671, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1026.8760, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1026.9849, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1027.0939, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145184.0 Parameter containing:\n",
      "tensor(1027.2029, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1027.3119, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1027.4210, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1027.5302, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1027.6393, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1027.7484, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1027.8577, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1027.9669, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1028.0762, requires_grad=True) tensor(1.) tensor(1.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119145176.0 Parameter containing:\n",
      "tensor(1028.1855, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1028.2949, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1028.4043, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1028.5138, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1028.6233, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1028.7328, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1028.8423, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1028.9519, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1029.0615, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1029.1711, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1029.2809, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1029.3906, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1029.5004, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1029.6102, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1029.7201, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1029.8300, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1029.9398, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1030.0498, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1030.1598, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1030.2698, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1030.3799, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1030.4900, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1030.6001, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1030.7102, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1030.8204, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1030.9307, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1031.0409, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1031.1512, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1031.2616, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1031.3719, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1031.4824, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1031.5929, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1031.7034, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1031.8138, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1031.9244, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1032.0350, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1032.1456, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1032.2563, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1032.3671, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1032.4778, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1032.5886, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1032.6995, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1032.8103, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1032.9211, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1033.0321, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1033.1431, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1033.2540, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1033.3651, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1033.4762, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1033.5873, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1033.6984, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1033.8096, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1033.9208, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1034.0320, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1034.1433, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1034.2546, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1034.3660, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145176.0 Parameter containing:\n",
      "tensor(1034.4774, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1034.5889, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1034.7003, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1034.8118, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1034.9233, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1035.0349, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1035.1465, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1035.2582, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1035.3699, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1035.4816, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1035.5933, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1035.7051, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1035.8169, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1035.9287, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1036.0406, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1036.1526, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1036.2645, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1036.3766, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1036.4886, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1036.6007, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1036.7128, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1036.8250, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1036.9371, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1037.0493, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1037.1616, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1037.2739, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1037.3862, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1037.4985, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1037.6110, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1037.7234, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1037.8358, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1037.9484, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1038.0609, requires_grad=True) tensor(1.) tensor(1.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119145168.0 Parameter containing:\n",
      "tensor(1038.1735, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1038.2861, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1038.3988, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1038.5115, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1038.6241, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1038.7369, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1038.8497, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1038.9625, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1039.0754, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1039.1884, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1039.3013, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1039.4142, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1039.5272, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1039.6403, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1039.7533, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1039.8665, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1039.9796, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1040.0928, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1040.2059, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1040.3192, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1040.4325, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1040.5458, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1040.6592, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1040.7726, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1040.8860, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1040.9994, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1041.1129, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1041.2264, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1041.3400, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1041.4536, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1041.5673, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1041.6809, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1041.7946, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1041.9083, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1042.0221, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1042.1359, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1042.2498, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1042.3636, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1042.4775, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1042.5916, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1042.7056, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1042.8196, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1042.9336, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1043.0477, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1043.1619, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1043.2760, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1043.3903, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1043.5045, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1043.6188, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1043.7330, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1043.8474, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1043.9618, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1044.0762, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1044.1907, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1044.3052, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1044.4197, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1044.5342, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1044.6488, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1044.7634, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1044.8781, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1044.9928, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1045.1075, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1045.2223, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1045.3370, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1045.4519, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1045.5668, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1045.6816, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145168.0 Parameter containing:\n",
      "tensor(1045.7966, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1045.9116, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1046.0266, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1046.1416, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1046.2567, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1046.3718, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1046.4869, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1046.6022, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1046.7174, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1046.8326, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1046.9479, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1047.0632, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1047.1786, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1047.2939, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1047.4094, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1047.5249, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1047.6404, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1047.7559, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1047.8715, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1047.9871, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1048.1027, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1048.2183, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1048.3340, requires_grad=True) tensor(1.) tensor(1.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119145160.0 Parameter containing:\n",
      "tensor(1048.4497, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1048.5654, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1048.6813, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1048.7971, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1048.9130, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1049.0288, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1049.1448, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1049.2607, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1049.3767, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1049.4928, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1049.6089, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1049.7250, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1049.8411, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1049.9573, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1050.0735, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1050.1897, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1050.3060, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1050.4224, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1050.5387, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1050.6550, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1050.7715, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1050.8879, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1051.0044, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1051.1210, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1051.2375, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1051.3541, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1051.4707, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1051.5874, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1051.7041, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1051.8208, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1051.9375, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1052.0543, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145160.0 Parameter containing:\n",
      "tensor(1052.1711, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1052.2880, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1052.4049, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1052.5219, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1052.6388, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1052.7557, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1052.8728, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1052.9899, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1053.1069, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1053.2241, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1053.3413, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1053.4585, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1053.5757, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1053.6930, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1053.8103, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1053.9276, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1054.0449, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1054.1624, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1054.2798, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1054.3972, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1054.5148, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1054.6323, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1054.7499, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1054.8674, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1054.9851, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1055.1028, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1055.2205, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1055.3383, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1055.4561, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1055.5739, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1055.6917, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1055.8096, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1055.9275, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1056.0454, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1056.1633, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1056.2814, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1056.3994, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1056.5175, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1056.6356, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1056.7538, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1056.8719, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1056.9901, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1057.1084, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1057.2267, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1057.3450, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1057.4633, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1057.5817, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1057.7001, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1057.8185, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1057.9370, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1058.0555, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1058.1741, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1058.2926, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1058.4113, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1058.5299, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1058.6486, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1058.7672, requires_grad=True) tensor(1.) tensor(1.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119145152.0 Parameter containing:\n",
      "tensor(1058.8860, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1059.0048, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1059.1235, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1059.2424, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1059.3613, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1059.4802, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1059.5991, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1059.7181, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1059.8372, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1059.9562, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1060.0752, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1060.1943, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1060.3135, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1060.4326, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1060.5519, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1060.6711, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1060.7904, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1060.9097, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1061.0291, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1061.1484, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1061.2678, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1061.3872, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1061.5067, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1061.6262, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1061.7457, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1061.8652, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1061.9849, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1062.1045, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1062.2241, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1062.3439, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145152.0 Parameter containing:\n",
      "tensor(1062.4636, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1062.5834, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1062.7031, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1062.8230, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1062.9429, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1063.0627, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1063.1826, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1063.3026, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1063.4226, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1063.5426, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1063.6626, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1063.7827, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1063.9028, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1064.0229, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1064.1432, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1064.2634, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1064.3837, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1064.5039, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1064.6243, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1064.7446, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1064.8650, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1064.9854, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1065.1058, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1065.2263, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1065.3468, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1065.4673, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1065.5879, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1065.7085, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1065.8291, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1065.9498, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1066.0706, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1066.1913, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1066.3120, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1066.4329, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1066.5537, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1066.6746, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1066.7954, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1066.9164, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1067.0374, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1067.1583, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1067.2793, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1067.4004, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1067.5215, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1067.6426, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1067.7637, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1067.8849, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145144.0 Parameter containing:\n",
      "tensor(1068.0061, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1068.1273, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1068.2485, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1068.3699, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1068.4912, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1068.6125, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1068.7340, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1068.8555, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1068.9769, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1069.0984, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1069.2200, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1069.3416, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1069.4631, requires_grad=True) tensor(1.) tensor(1.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119145136.0 Parameter containing:\n",
      "tensor(1069.5847, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1069.7064, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1069.8281, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1069.9498, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1070.0715, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145128.0 Parameter containing:\n",
      "tensor(1070.1934, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145128.0 Parameter containing:\n",
      "tensor(1070.3152, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1070.4370, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1070.5588, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1070.6808, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1070.8027, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1070.9247, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1071.0466, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1071.1687, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1071.2908, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1071.4128, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1071.5349, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1071.6571, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1071.7793, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1071.9015, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1072.0237, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1072.1460, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1072.2683, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1072.3906, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1072.5131, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1072.6355, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1072.7579, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1072.8804, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1073.0029, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1073.1255, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1073.2480, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1073.3706, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1073.4933, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1073.6160, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1073.7386, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1073.8613, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1073.9841, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1074.1069, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1074.2297, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1074.3525, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1074.4755, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1074.5984, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1074.7213, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1074.8442, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1074.9673, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1075.0903, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1075.2134, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1075.3364, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1075.4596, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1075.5828, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1075.7059, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1075.8291, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1075.9524, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1076.0757, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1076.1990, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1076.3223, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1076.4457, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1076.5691, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1076.6925, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1076.8159, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1076.9395, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1077.0630, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145136.0 Parameter containing:\n",
      "tensor(1077.1865, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1077.3101, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1077.4337, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1077.5574, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1077.6810, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1077.8047, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1077.9285, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1078.0522, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1078.1760, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1078.2998, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1078.4237, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1078.5476, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1078.6715, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1078.7954, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1078.9194, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1079.0435, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1079.1675, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1079.2915, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1079.4156, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1079.5398, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1079.6639, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1079.7881, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1079.9124, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1080.0366, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1080.1609, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1080.2852, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1080.4095, requires_grad=True) tensor(1.) tensor(1.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119145120.0 Parameter containing:\n",
      "tensor(1080.5339, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1080.6583, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1080.7827, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1080.9072, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1081.0317, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1081.1562, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1081.2808, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1081.4053, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1081.5299, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1081.6545, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1081.7792, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1081.9038, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1082.0286, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1082.1533, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1082.2781, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1082.4028, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1082.5277, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1082.6526, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1082.7775, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1082.9023, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1083.0273, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1083.1523, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1083.2773, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1083.4023, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1083.5275, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1083.6526, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1083.7777, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1083.9028, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1084.0281, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1084.1533, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1084.2786, requires_grad=True) tensor(1.) tensor(1.)\n",
      "119145120.0 Parameter containing:\n",
      "tensor(1084.4038, requires_grad=True) tensor(1.) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    model.zero_grad()\n",
    "    loss = model(X, one_hot_y, m)\n",
    "    loss = torch.clamp(loss, min=1e-20, max=1e20)\n",
    "    print(loss.item(), model.lengthscale, model.noise, model.outputscale)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([962, 453, 676, 935, 823, 107, 237, 405, 846, 532, 140, 163, 145, 422,\n",
      "        590, 501, 209, 883,  30, 700,  15, 339, 931, 426, 460, 623, 679, 738,\n",
      "        684, 256, 838, 965, 339, 802, 369, 332, 316, 543, 827, 935, 580, 231,\n",
      "        533, 649, 173, 487, 538, 182, 185, 577, 429, 382, 409, 948, 453, 103,\n",
      "        423, 748, 615, 567, 209, 265, 188, 135, 987, 901, 249, 646, 435, 154,\n",
      "        585, 694, 110, 430, 451,  58,  49,  72, 952, 925, 361, 858, 289, 874,\n",
      "        134, 262, 716, 914, 937, 400, 940, 337, 165, 655, 492, 337, 261, 285,\n",
      "        196, 999])\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "class MyMean(gpytorch.means.Mean):\n",
    "    def __init__(self, num_classes=1_000):\n",
    "        super().__init__()\n",
    "        self.resnet50 = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            logits = self.resnet50(x)\n",
    "            probas = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        return probas.t()\n",
    "    \n",
    "class DirichletGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, X, y, likelihood, num_classes):\n",
    "        super(DirichletGPModel, self).__init__(X, y, likelihood)\n",
    "        self.mean_module = MyMean(num_classes)\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel(batch_shape=torch.Size((num_classes,))),\n",
    "            batch_shape=torch.Size((num_classes,)),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x.view(x.shape[0], -1))\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "X = torch.stack([image for image, label in subset_train_dataset])\n",
    "y = torch.stack([torch.tensor(label) for image, label in subset_train_dataset])\n",
    "print(y)\n",
    "\n",
    "# initialize likelihood and model\n",
    "# we let the DirichletClassificationLikelihood compute the targets for us\n",
    "likelihood = gpytorch.likelihoods.DirichletClassificationLikelihood(y, learn_additional_noise=True)\n",
    "print(likelihood.num_classes)\n",
    "model = DirichletGPModel(X, likelihood.transformed_targets, likelihood, num_classes=1_000)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam([likelihood.second_noise_covar.raw_noise, \n",
    "                              model.covar_module.raw_outputscale,\n",
    "                              model.covar_module.base_kernel.raw_lengthscale], lr=0.1)\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likelihood.second_noise_covar.raw_noise\n",
      "mean_module.resnet50.conv1.weight\n",
      "mean_module.resnet50.bn1.weight\n",
      "mean_module.resnet50.bn1.bias\n",
      "mean_module.resnet50.layer1.0.conv1.weight\n",
      "mean_module.resnet50.layer1.0.bn1.weight\n",
      "mean_module.resnet50.layer1.0.bn1.bias\n",
      "mean_module.resnet50.layer1.0.conv2.weight\n",
      "mean_module.resnet50.layer1.0.bn2.weight\n",
      "mean_module.resnet50.layer1.0.bn2.bias\n",
      "mean_module.resnet50.layer1.0.conv3.weight\n",
      "mean_module.resnet50.layer1.0.bn3.weight\n",
      "mean_module.resnet50.layer1.0.bn3.bias\n",
      "mean_module.resnet50.layer1.0.downsample.0.weight\n",
      "mean_module.resnet50.layer1.0.downsample.1.weight\n",
      "mean_module.resnet50.layer1.0.downsample.1.bias\n",
      "mean_module.resnet50.layer1.1.conv1.weight\n",
      "mean_module.resnet50.layer1.1.bn1.weight\n",
      "mean_module.resnet50.layer1.1.bn1.bias\n",
      "mean_module.resnet50.layer1.1.conv2.weight\n",
      "mean_module.resnet50.layer1.1.bn2.weight\n",
      "mean_module.resnet50.layer1.1.bn2.bias\n",
      "mean_module.resnet50.layer1.1.conv3.weight\n",
      "mean_module.resnet50.layer1.1.bn3.weight\n",
      "mean_module.resnet50.layer1.1.bn3.bias\n",
      "mean_module.resnet50.layer1.2.conv1.weight\n",
      "mean_module.resnet50.layer1.2.bn1.weight\n",
      "mean_module.resnet50.layer1.2.bn1.bias\n",
      "mean_module.resnet50.layer1.2.conv2.weight\n",
      "mean_module.resnet50.layer1.2.bn2.weight\n",
      "mean_module.resnet50.layer1.2.bn2.bias\n",
      "mean_module.resnet50.layer1.2.conv3.weight\n",
      "mean_module.resnet50.layer1.2.bn3.weight\n",
      "mean_module.resnet50.layer1.2.bn3.bias\n",
      "mean_module.resnet50.layer2.0.conv1.weight\n",
      "mean_module.resnet50.layer2.0.bn1.weight\n",
      "mean_module.resnet50.layer2.0.bn1.bias\n",
      "mean_module.resnet50.layer2.0.conv2.weight\n",
      "mean_module.resnet50.layer2.0.bn2.weight\n",
      "mean_module.resnet50.layer2.0.bn2.bias\n",
      "mean_module.resnet50.layer2.0.conv3.weight\n",
      "mean_module.resnet50.layer2.0.bn3.weight\n",
      "mean_module.resnet50.layer2.0.bn3.bias\n",
      "mean_module.resnet50.layer2.0.downsample.0.weight\n",
      "mean_module.resnet50.layer2.0.downsample.1.weight\n",
      "mean_module.resnet50.layer2.0.downsample.1.bias\n",
      "mean_module.resnet50.layer2.1.conv1.weight\n",
      "mean_module.resnet50.layer2.1.bn1.weight\n",
      "mean_module.resnet50.layer2.1.bn1.bias\n",
      "mean_module.resnet50.layer2.1.conv2.weight\n",
      "mean_module.resnet50.layer2.1.bn2.weight\n",
      "mean_module.resnet50.layer2.1.bn2.bias\n",
      "mean_module.resnet50.layer2.1.conv3.weight\n",
      "mean_module.resnet50.layer2.1.bn3.weight\n",
      "mean_module.resnet50.layer2.1.bn3.bias\n",
      "mean_module.resnet50.layer2.2.conv1.weight\n",
      "mean_module.resnet50.layer2.2.bn1.weight\n",
      "mean_module.resnet50.layer2.2.bn1.bias\n",
      "mean_module.resnet50.layer2.2.conv2.weight\n",
      "mean_module.resnet50.layer2.2.bn2.weight\n",
      "mean_module.resnet50.layer2.2.bn2.bias\n",
      "mean_module.resnet50.layer2.2.conv3.weight\n",
      "mean_module.resnet50.layer2.2.bn3.weight\n",
      "mean_module.resnet50.layer2.2.bn3.bias\n",
      "mean_module.resnet50.layer2.3.conv1.weight\n",
      "mean_module.resnet50.layer2.3.bn1.weight\n",
      "mean_module.resnet50.layer2.3.bn1.bias\n",
      "mean_module.resnet50.layer2.3.conv2.weight\n",
      "mean_module.resnet50.layer2.3.bn2.weight\n",
      "mean_module.resnet50.layer2.3.bn2.bias\n",
      "mean_module.resnet50.layer2.3.conv3.weight\n",
      "mean_module.resnet50.layer2.3.bn3.weight\n",
      "mean_module.resnet50.layer2.3.bn3.bias\n",
      "mean_module.resnet50.layer3.0.conv1.weight\n",
      "mean_module.resnet50.layer3.0.bn1.weight\n",
      "mean_module.resnet50.layer3.0.bn1.bias\n",
      "mean_module.resnet50.layer3.0.conv2.weight\n",
      "mean_module.resnet50.layer3.0.bn2.weight\n",
      "mean_module.resnet50.layer3.0.bn2.bias\n",
      "mean_module.resnet50.layer3.0.conv3.weight\n",
      "mean_module.resnet50.layer3.0.bn3.weight\n",
      "mean_module.resnet50.layer3.0.bn3.bias\n",
      "mean_module.resnet50.layer3.0.downsample.0.weight\n",
      "mean_module.resnet50.layer3.0.downsample.1.weight\n",
      "mean_module.resnet50.layer3.0.downsample.1.bias\n",
      "mean_module.resnet50.layer3.1.conv1.weight\n",
      "mean_module.resnet50.layer3.1.bn1.weight\n",
      "mean_module.resnet50.layer3.1.bn1.bias\n",
      "mean_module.resnet50.layer3.1.conv2.weight\n",
      "mean_module.resnet50.layer3.1.bn2.weight\n",
      "mean_module.resnet50.layer3.1.bn2.bias\n",
      "mean_module.resnet50.layer3.1.conv3.weight\n",
      "mean_module.resnet50.layer3.1.bn3.weight\n",
      "mean_module.resnet50.layer3.1.bn3.bias\n",
      "mean_module.resnet50.layer3.2.conv1.weight\n",
      "mean_module.resnet50.layer3.2.bn1.weight\n",
      "mean_module.resnet50.layer3.2.bn1.bias\n",
      "mean_module.resnet50.layer3.2.conv2.weight\n",
      "mean_module.resnet50.layer3.2.bn2.weight\n",
      "mean_module.resnet50.layer3.2.bn2.bias\n",
      "mean_module.resnet50.layer3.2.conv3.weight\n",
      "mean_module.resnet50.layer3.2.bn3.weight\n",
      "mean_module.resnet50.layer3.2.bn3.bias\n",
      "mean_module.resnet50.layer3.3.conv1.weight\n",
      "mean_module.resnet50.layer3.3.bn1.weight\n",
      "mean_module.resnet50.layer3.3.bn1.bias\n",
      "mean_module.resnet50.layer3.3.conv2.weight\n",
      "mean_module.resnet50.layer3.3.bn2.weight\n",
      "mean_module.resnet50.layer3.3.bn2.bias\n",
      "mean_module.resnet50.layer3.3.conv3.weight\n",
      "mean_module.resnet50.layer3.3.bn3.weight\n",
      "mean_module.resnet50.layer3.3.bn3.bias\n",
      "mean_module.resnet50.layer3.4.conv1.weight\n",
      "mean_module.resnet50.layer3.4.bn1.weight\n",
      "mean_module.resnet50.layer3.4.bn1.bias\n",
      "mean_module.resnet50.layer3.4.conv2.weight\n",
      "mean_module.resnet50.layer3.4.bn2.weight\n",
      "mean_module.resnet50.layer3.4.bn2.bias\n",
      "mean_module.resnet50.layer3.4.conv3.weight\n",
      "mean_module.resnet50.layer3.4.bn3.weight\n",
      "mean_module.resnet50.layer3.4.bn3.bias\n",
      "mean_module.resnet50.layer3.5.conv1.weight\n",
      "mean_module.resnet50.layer3.5.bn1.weight\n",
      "mean_module.resnet50.layer3.5.bn1.bias\n",
      "mean_module.resnet50.layer3.5.conv2.weight\n",
      "mean_module.resnet50.layer3.5.bn2.weight\n",
      "mean_module.resnet50.layer3.5.bn2.bias\n",
      "mean_module.resnet50.layer3.5.conv3.weight\n",
      "mean_module.resnet50.layer3.5.bn3.weight\n",
      "mean_module.resnet50.layer3.5.bn3.bias\n",
      "mean_module.resnet50.layer4.0.conv1.weight\n",
      "mean_module.resnet50.layer4.0.bn1.weight\n",
      "mean_module.resnet50.layer4.0.bn1.bias\n",
      "mean_module.resnet50.layer4.0.conv2.weight\n",
      "mean_module.resnet50.layer4.0.bn2.weight\n",
      "mean_module.resnet50.layer4.0.bn2.bias\n",
      "mean_module.resnet50.layer4.0.conv3.weight\n",
      "mean_module.resnet50.layer4.0.bn3.weight\n",
      "mean_module.resnet50.layer4.0.bn3.bias\n",
      "mean_module.resnet50.layer4.0.downsample.0.weight\n",
      "mean_module.resnet50.layer4.0.downsample.1.weight\n",
      "mean_module.resnet50.layer4.0.downsample.1.bias\n",
      "mean_module.resnet50.layer4.1.conv1.weight\n",
      "mean_module.resnet50.layer4.1.bn1.weight\n",
      "mean_module.resnet50.layer4.1.bn1.bias\n",
      "mean_module.resnet50.layer4.1.conv2.weight\n",
      "mean_module.resnet50.layer4.1.bn2.weight\n",
      "mean_module.resnet50.layer4.1.bn2.bias\n",
      "mean_module.resnet50.layer4.1.conv3.weight\n",
      "mean_module.resnet50.layer4.1.bn3.weight\n",
      "mean_module.resnet50.layer4.1.bn3.bias\n",
      "mean_module.resnet50.layer4.2.conv1.weight\n",
      "mean_module.resnet50.layer4.2.bn1.weight\n",
      "mean_module.resnet50.layer4.2.bn1.bias\n",
      "mean_module.resnet50.layer4.2.conv2.weight\n",
      "mean_module.resnet50.layer4.2.bn2.weight\n",
      "mean_module.resnet50.layer4.2.bn2.bias\n",
      "mean_module.resnet50.layer4.2.conv3.weight\n",
      "mean_module.resnet50.layer4.2.bn3.weight\n",
      "mean_module.resnet50.layer4.2.bn3.bias\n",
      "mean_module.resnet50.fc.weight\n",
      "mean_module.resnet50.fc.bias\n",
      "covar_module.raw_outputscale\n",
      "covar_module.base_kernel.raw_lengthscale\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 56.08 GiB (GPU 0; 39.39 GiB total capacity; 1005.76 MiB already allocated; 36.68 GiB free; 1.02 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[149], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      4\u001b[0m output \u001b[38;5;241m=\u001b[39m model(X)\n\u001b[0;32m----> 5\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[43mmll\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformed_targets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n\u001b[1;32m      7\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/bdl-transfer-learning/lib/python3.8/site-packages/gpytorch/module.py:31\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, Distribution, LinearOperator]:\n\u001b[0;32m---> 31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/bdl-transfer-learning/lib/python3.8/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py:64\u001b[0m, in \u001b[0;36mExactMarginalLogLikelihood.forward\u001b[0;34m(self, function_dist, target, *params)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Get the log prob of the marginal distribution\u001b[39;00m\n\u001b[1;32m     63\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlikelihood(function_dist, \u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m---> 64\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_other_terms(res, params)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Scale by the amount of data we have\u001b[39;00m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/bdl-transfer-learning/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:192\u001b[0m, in \u001b[0;36mMultivariateNormal.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    185\u001b[0m         covar \u001b[38;5;241m=\u001b[39m covar\u001b[38;5;241m.\u001b[39mrepeat(\n\u001b[1;32m    186\u001b[0m             \u001b[38;5;241m*\u001b[39m(diff_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m covar_size \u001b[38;5;28;01mfor\u001b[39;00m diff_size, covar_size \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(diff\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], padded_batch_shape)),\n\u001b[1;32m    187\u001b[0m             \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    188\u001b[0m             \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    189\u001b[0m         )\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# Get log determininant and first part of quadratic form\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m covar \u001b[38;5;241m=\u001b[39m \u001b[43mcovar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m inv_quad, logdet \u001b[38;5;241m=\u001b[39m covar\u001b[38;5;241m.\u001b[39minv_quad_logdet(inv_quad_rhs\u001b[38;5;241m=\u001b[39mdiff\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), logdet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    195\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28msum\u001b[39m([inv_quad, logdet, diff\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mpi)])\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/bdl-transfer-learning/lib/python3.8/site-packages/linear_operator/operators/added_diag_linear_operator.py:209\u001b[0m, in \u001b[0;36mAddedDiagLinearOperator.evaluate_kernel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_kernel\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 209\u001b[0m     added_diag_linear_op \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresentation_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepresentation())\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m added_diag_linear_op\u001b[38;5;241m.\u001b[39m_linear_op \u001b[38;5;241m+\u001b[39m added_diag_linear_op\u001b[38;5;241m.\u001b[39m_diag_tensor\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/bdl-transfer-learning/lib/python3.8/site-packages/linear_operator/operators/_linear_operator.py:2064\u001b[0m, in \u001b[0;36mLinearOperator.representation_tree\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2054\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrepresentation_tree\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LinearOperatorRepresentationTree:\n\u001b[1;32m   2055\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2056\u001b[0m \u001b[38;5;124;03m    Returns a\u001b[39;00m\n\u001b[1;32m   2057\u001b[0m \u001b[38;5;124;03m    :obj:`linear_operator.operators.LinearOperatorRepresentationTree` tree\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2062\u001b[0m \u001b[38;5;124;03m    including all subobjects. This is used internally.\u001b[39;00m\n\u001b[1;32m   2063\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLinearOperatorRepresentationTree\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/bdl-transfer-learning/lib/python3.8/site-packages/linear_operator/operators/linear_operator_representation_tree.py:15\u001b[0m, in \u001b[0;36mLinearOperatorRepresentationTree.__init__\u001b[0;34m(self, linear_op)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(linear_op\u001b[38;5;241m.\u001b[39m_args, linear_op\u001b[38;5;241m.\u001b[39m_differentiable_kwargs\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepresentation\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(arg\u001b[38;5;241m.\u001b[39mrepresentation):  \u001b[38;5;66;03m# Is it a lazy tensor?\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m         representation_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;28mslice\u001b[39m(counter, counter \u001b[38;5;241m+\u001b[39m representation_size, \u001b[38;5;28;01mNone\u001b[39;00m), arg\u001b[38;5;241m.\u001b[39mrepresentation_tree()))\n\u001b[1;32m     17\u001b[0m         counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m representation_size\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/bdl-transfer-learning/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py:397\u001b[0m, in \u001b[0;36mLazyEvaluatedKernelTensor.representation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrepresentation()\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# Otherwise, we'll evaluate the kernel (or at least its LinearOperator representation) and use its\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;66;03m# representation\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mrepresentation()\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/bdl-transfer-learning/lib/python3.8/site-packages/gpytorch/utils/memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m kwargs_pkl \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mdumps(kwargs)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_in_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl):\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _add_to_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_from_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/bdl-transfer-learning/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py:25\u001b[0m, in \u001b[0;36mrecall_grad_state.<locals>.wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(method)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_grad_enabled):\n\u001b[0;32m---> 25\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/bdl-transfer-learning/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py:355\u001b[0m, in \u001b[0;36mLazyEvaluatedKernelTensor.evaluate_kernel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    353\u001b[0m     temp_active_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 355\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdiag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims \u001b[38;5;241m=\u001b[39m temp_active_dims\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m# Check the size of the output\u001b[39;00m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/bdl-transfer-learning/lib/python3.8/site-packages/gpytorch/kernels/kernel.py:530\u001b[0m, in \u001b[0;36mKernel.__call__\u001b[0;34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001b[0m\n\u001b[1;32m    527\u001b[0m     res \u001b[38;5;241m=\u001b[39m LazyEvaluatedKernelTensor(x1_, x2_, kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, last_dim_is_batch\u001b[38;5;241m=\u001b[39mlast_dim_is_batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     res \u001b[38;5;241m=\u001b[39m to_linear_operator(\n\u001b[0;32m--> 530\u001b[0m         \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mKernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx1_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m     )\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/bdl-transfer-learning/lib/python3.8/site-packages/gpytorch/module.py:31\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, Distribution, LinearOperator]:\n\u001b[0;32m---> 31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/bdl-transfer-learning/lib/python3.8/site-packages/gpytorch/kernels/scale_kernel.py:109\u001b[0m, in \u001b[0;36mScaleKernel.forward\u001b[0;34m(self, x1, x2, last_dim_is_batch, diag, **params)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x1, x2, last_dim_is_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, diag\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[0;32m--> 109\u001b[0m     orig_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_kernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     outputscales \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputscale\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m last_dim_is_batch:\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/bdl-transfer-learning/lib/python3.8/site-packages/gpytorch/kernels/rbf_kernel.py:80\u001b[0m, in \u001b[0;36mRBFKernel.forward\u001b[0;34m(self, x1, x2, diag, **params)\u001b[0m\n\u001b[1;32m     78\u001b[0m     x2_ \u001b[38;5;241m=\u001b[39m x2\u001b[38;5;241m.\u001b[39mdiv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlengthscale)\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m postprocess_rbf(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovar_dist(x1_, x2_, square_dist\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, diag\u001b[38;5;241m=\u001b[39mdiag, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams))\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mRBFCovariance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlengthscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcovar_dist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquare_dist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/bdl-transfer-learning/lib/python3.8/site-packages/gpytorch/functions/rbf_covariance.py:12\u001b[0m, in \u001b[0;36mRBFCovariance.forward\u001b[0;34m(ctx, x1, x2, lengthscale, sq_dist_func)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRBFCovariance cannot handle multiple lengthscales\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m needs_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(ctx\u001b[38;5;241m.\u001b[39mneeds_input_grad)\n\u001b[0;32m---> 12\u001b[0m x1_ \u001b[38;5;241m=\u001b[39m \u001b[43mx1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlengthscale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m x2_ \u001b[38;5;241m=\u001b[39m x2\u001b[38;5;241m.\u001b[39mdiv(lengthscale)\n\u001b[1;32m     14\u001b[0m unitless_sq_dist \u001b[38;5;241m=\u001b[39m sq_dist_func(x1_, x2_)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 56.08 GiB (GPU 0; 39.39 GiB total capacity; 1005.76 MiB already allocated; 36.68 GiB free; 1.02 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "X, y = X.to(device), y.to(device)\n",
    "for i in range(10):\n",
    "    model.zero_grad()\n",
    "    output = model(X)\n",
    "    loss = -mll(output, likelihood.transformed_targets.to(device)).sum()\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdl-transfer-learning",
   "language": "python",
   "name": "bdl-transfer-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
